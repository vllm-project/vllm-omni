# Two-stage config for MammothModa2 (AR -> DiT).
# 参考 qwen2_5_omni 的做法：两个 stage 都使用同一个入口模型（model_arch），
# 再通过 engine_args.model_stage（ar/dit）决定实际初始化哪个子模块。
stage_args:
  - stage_id: 0
    runtime:
      devices: "0"
      max_batch_size: 1
    engine_args:
      model_stage: ar
      model_arch: MammothModa2ForConditionalGeneration
      worker_cls: vllm_omni.worker.gpu_ar_worker.GPUARWorker
      scheduler_cls: vllm_omni.core.sched.omni_ar_scheduler.OmniARScheduler
      # 文生图用不到 128k 上下文，显式限制 max_model_len 以降低 KV cache 需求，
      # 避免 vLLM 在启动时因 “max seq len 太大” 直接报错。
      max_model_len: 8192
      # AR 与 DiT 在单卡上需要共享显存；默认 0.9 会导致 stage-1 启动时可用显存不足。
      # 这里显式降低，以便两阶段可以在同一张 GPU 上同时驻留。
      gpu_memory_utilization: 0.3
      enforce_eager: true
      trust_remote_code: true
      engine_output_type: latent
      enable_prefix_caching: false
    final_output: false

  - stage_id: 1
    runtime:
      devices: "0"
      max_batch_size: 1
    engine_args:
      model_stage: dit
      model_arch: MammothModa2ForConditionalGeneration
      # NOTE: GPUGenerationModelRunner 不会透传 additional/runtime_additional_information，
      # DiT 需要从上游 AR hidden states 构造的 condition embedding，因此这里复用 AR runner 路径。
      worker_cls: vllm_omni.worker.gpu_ar_worker.GPUARWorker
      scheduler_cls: vllm_omni.core.sched.omni_ar_scheduler.OmniARScheduler
      # 同上：避免 stage-0 预留过多显存导致 stage-1 init_device 直接报错。
      gpu_memory_utilization: 0.3
      enforce_eager: true
      trust_remote_code: true
      # 避免 output processor 将 "hidden" 重命名为 "image" 覆盖真实图像输出
      engine_output_type: text+image
      max_model_len: 16
      enable_prefix_caching: false
    engine_input_source: [0]
    custom_process_input_func: vllm_omni.model_executor.stage_input_processors.mammoth_moda2.ar2dit
    final_output: true
    final_output_type: image
